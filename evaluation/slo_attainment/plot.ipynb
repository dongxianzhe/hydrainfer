{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Get current working directory (notebook location)\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Path to the \"results\" folder\n",
    "results_dir = os.path.join(base_dir, 'result')\n",
    "\n",
    "# Path to the figure output dir\n",
    "figures_dir = os.path.join(base_dir, 'figure')\n",
    "\n",
    "# Regex pattern to match folders like \"20250425_080607\"\n",
    "date_pattern = re.compile(r'^\\d{8}_\\d{6}$')\n",
    "\n",
    "# List to store all parsed JSON data\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all subdirectories in \"results\"\n",
    "for folder_name in os.listdir(results_dir):\n",
    "    folder_path = os.path.join(results_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path) and date_pattern.match(folder_name):\n",
    "        print(f\"Reading folder: {folder_path}\")\n",
    "        \n",
    "        # Iterate through all JSON files in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.json'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                        print(f\"Loaded file: {file_path}\")\n",
    "                        all_data.append(data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_dataset_to_logs = {} # model: str, dataset: str -> list[log]\n",
    "models = set()\n",
    "datasets = set()\n",
    "methods = set()\n",
    "\n",
    "for data in all_data:\n",
    "    model = data['model']\n",
    "    dataset: str = \"\"\n",
    "    if sum(1 for v in data['datasets'].values() if v != 0) > 1:\n",
    "        dataset = 'mixed'\n",
    "    else:\n",
    "        dataset = next(k for k, v in data['datasets'].items() if v != 0)\n",
    "        \n",
    "    models.add(model)\n",
    "    datasets.add(dataset)\n",
    "    methods.add(data['method_name'])\n",
    "        \n",
    "    if (model, dataset) not in model_dataset_to_logs:\n",
    "        model_dataset_to_logs[model, dataset] = []\n",
    "    model_dataset_to_logs[model, dataset].append(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2c4bf66863b29a7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_models = len(models)\n",
    "n_datasets = len(datasets)\n",
    "n_methods = len(methods)\n",
    "\n",
    "print(f'models: {models}')\n",
    "print(f'datasets {datasets}')\n",
    "print(f'methods {methods}')\n",
    "\n",
    "print(f'number of models {n_models}')\n",
    "print(f'number of datasets {n_datasets}')\n",
    "print(f'number of methods {methods}')\n",
    "\n",
    "for (model, dataset), methods_data in model_dataset_to_logs.items():\n",
    "    print(f'number of methods {len(methods_data)}', model, dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dc065306ccd2d24",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "# caculate all slo settings to select best TTFT SLOs and TPOT SLOs\n",
    "TTFT_SLOs = [1, 2, 3, 4, 5, 8, 10, 12, 15, 16]\n",
    "TPOT_SLOs = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]\n",
    "\n",
    "@dataclass\n",
    "class LineData:\n",
    "    model: str\n",
    "    dataset: str\n",
    "    ttft_slo: float\n",
    "    tpot_slo: float\n",
    "    method: str\n",
    "    request_rates: list[float]\n",
    "    n_output_tokens: list[int]\n",
    "    avg_latency: list[float]\n",
    "    p90_latency: list[float]\n",
    "    p99_latency: list[float]\n",
    "    avg_ttft: list[float]\n",
    "    p90_ttft: list[float]\n",
    "    p99_ttft: list[float]\n",
    "    avg_tpot: list[float]\n",
    "    p90_tpot: list[float]\n",
    "    p99_tpot: list[float]\n",
    "    ttft_slo_attainment: list[float]\n",
    "    tpot_slo_attainment: list[float]\n",
    "    slo_attainment: list[float]\n",
    "    \n",
    "all_line_data: list[LineData] = []\n",
    "selected_line_data: list[LineData] = []\n",
    "\n",
    "for (model, dataset), methods_data in model_dataset_to_logs.items():\n",
    "    candidate_line_data: dict[tuple[float, float], list[LineData]] = {(ttft, tpot) : [] for ttft in TTFT_SLOs for tpot in TPOT_SLOs}\n",
    "    for TTFT_SLO in TTFT_SLOs:\n",
    "        for TPOT_SLO in TPOT_SLOs:\n",
    "            for method_data in methods_data:\n",
    "                request_rates: list[float] = []\n",
    "                n_output_tokens: list[int] = []\n",
    "                avg_latency: list[float] = [] \n",
    "                p90_latency: list[float] = [] \n",
    "                p99_latency: list[float] = [] \n",
    "                avg_ttft: list[float] = [] \n",
    "                p90_ttft: list[float] = [] \n",
    "                p99_ttft: list[float] = [] \n",
    "                avg_tpot: list[float] = [] \n",
    "                p90_tpot: list[float] = [] \n",
    "                p99_tpot: list[float] = [] \n",
    "                tpot_slo_attainment: list[float] = []\n",
    "                ttft_slo_attainment: list[float] = []\n",
    "                slo_attainment: list[float] = []\n",
    "                \n",
    "                method = method_data['method_name']\n",
    "                results = method_data['results']\n",
    "                for result in results:\n",
    "                    all_ttfts: list[float] = []\n",
    "                    all_tpots: list[float] = []\n",
    "                    all_latencies: list[float] = []\n",
    "                    sum_output_tokens: int = 0\n",
    "                    request_rate = result['request_rate']\n",
    "                    outputs = result['outputs']\n",
    "                    total_requests = len(outputs)\n",
    "\n",
    "                    ttft_satisfied_cnt = 0\n",
    "                    tpot_satisfied_cnt = 0\n",
    "                    satisfied_cnt = 0\n",
    "                    for output in outputs:\n",
    "                        start_time = output['start_time']\n",
    "                        token_times = output['token_times']\n",
    "                        latency = token_times[-1] - start_time\n",
    "                        ttft = token_times[0] - start_time\n",
    "                        tpots = [token_times[i] - token_times[i - 1] for i in range(1, len(token_times))]\n",
    "                        ttft_satisfied = ttft < TTFT_SLO\n",
    "                        tpot_satisfied = max(tpots) < TPOT_SLO\n",
    "                        satisfied = ttft_satisfied and tpot_satisfied\n",
    "                        ttft_satisfied_cnt += ttft_satisfied\n",
    "                        tpot_satisfied_cnt += tpot_satisfied\n",
    "                        satisfied_cnt += satisfied\n",
    "                        all_ttfts.append(ttft)\n",
    "                        all_tpots += tpots\n",
    "                        all_latencies.append(latency)\n",
    "                        sum_output_tokens += len(token_times)\n",
    "\n",
    "                    request_rates.append(request_rate)\n",
    "                    n_output_tokens.append(sum_output_tokens)\n",
    "                    avg_latency.append(np.mean(all_latencies))\n",
    "                    p90_latency.append(np.percentile(all_latencies, 90))\n",
    "                    p99_latency.append(np.percentile(all_latencies, 99))\n",
    "                    avg_ttft.append(np.mean(all_ttfts))\n",
    "                    p90_ttft.append(np.percentile(all_ttfts, 90))\n",
    "                    p99_ttft.append(np.percentile(all_ttfts, 99))\n",
    "                    avg_tpot.append(np.mean(all_tpots))\n",
    "                    p90_tpot.append(np.percentile(all_tpots, 90))\n",
    "                    p99_tpot.append(np.percentile(all_tpots, 99))\n",
    "                    ttft_slo_attainment.append(ttft_satisfied_cnt / total_requests)\n",
    "                    tpot_slo_attainment.append(tpot_satisfied_cnt / total_requests)\n",
    "                    slo_attainment.append(satisfied_cnt / total_requests)\n",
    "                line_data = LineData(\n",
    "                    model               = model, \n",
    "                    dataset             = dataset, \n",
    "                    ttft_slo            = TTFT_SLO, \n",
    "                    tpot_slo            = TPOT_SLO, \n",
    "                    method              = method, \n",
    "                    request_rates       = request_rates, \n",
    "                    n_output_tokens     = n_output_tokens, \n",
    "                    avg_latency         = avg_latency, \n",
    "                    p90_latency         = p90_latency, \n",
    "                    p99_latency         = p99_latency, \n",
    "                    avg_ttft            = avg_ttft, \n",
    "                    p90_ttft            = p90_ttft, \n",
    "                    p99_ttft            = p99_ttft, \n",
    "                    avg_tpot            = avg_tpot, \n",
    "                    p90_tpot            = p90_tpot, \n",
    "                    p99_tpot            = p99_tpot, \n",
    "                    ttft_slo_attainment = ttft_slo_attainment, \n",
    "                    tpot_slo_attainment = tpot_slo_attainment, \n",
    "                    slo_attainment      = slo_attainment, \n",
    "                )\n",
    "                all_line_data.append(line_data)\n",
    "                candidate_line_data[(TTFT_SLO, TPOT_SLO)].append(line_data)\n",
    "    \n",
    "    # select ttft_slo and tpot_slo\n",
    "    best_slo_settings: tuple[float, float] = (0, 0)\n",
    "    max_avg_var = 0.\n",
    "    for (tpot_slo, ttft_slo), methods_line_data in candidate_line_data.items():\n",
    "        data = np.vstack([method_line_data.slo_attainment for method_line_data in methods_line_data]) # (n_methods, n_request_rate)\n",
    "        var_per_x = np.var(data, axis=0, ddof=0) # (n_request_rate)\n",
    "        avg_var = np.mean(var_per_x)\n",
    "        if avg_var > max_avg_var:\n",
    "            max_avg_var = avg_var\n",
    "            best_slo_settings = (tpot_slo, ttft_slo)\n",
    "    print(f'{model} {dataset} best slo settings {best_slo_settings}')\n",
    "    selected_line_data += candidate_line_data[best_slo_settings]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2118d4dbd710e3ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# visualize selected line\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def get_intersection_points(x, y, target_y) -> list[tuple[float, float]]:\n",
    "    cross_points = []\n",
    "\n",
    "    # Check if y_i is close to target_y\n",
    "    for xi, yi in zip(x, y):\n",
    "        if np.isclose(yi, target_y):\n",
    "            cross_points.append((xi, yi))\n",
    "\n",
    "    # Check if each line crosses the y=target_y line\n",
    "    for i in range(len(x) - 1):\n",
    "        x0, x1 = x[i], x[i + 1]\n",
    "        y0, y1 = y[i], y[i + 1]\n",
    "        if (y0 - target_y) * (y1 - target_y) < 0:\n",
    "            t = (target_y - y0) / (y1 - y0)\n",
    "            x_inter = x0 + t * (x1 - x0)\n",
    "            y_inter = y0 + t * (y1 - y0)\n",
    "            cross_points.append((x_inter, y_inter))\n",
    "\n",
    "    return cross_points\n",
    "\n",
    "def draw_slo_vertical_line(x_values, y_values, slo_target, ax, **kwargs):\n",
    "    cross_points = get_intersection_points(x_values, y_values, slo_target)\n",
    "    if not cross_points:\n",
    "        if y_values[0] < slo_target:\n",
    "            ax.plot([x_values[0], x_values[0]], [-5, y_values[0]], **kwargs)\n",
    "        elif y_values[-1] > slo_target:\n",
    "            ax.plot([x_values[-1], x_values[-1]], [-5, y_values[-1]], **kwargs)\n",
    "    for x, y in cross_points:\n",
    "        ax.plot([x, x], [0, y], **kwargs)\n",
    "\n",
    "n_rows = n_models\n",
    "n_cols = n_datasets\n",
    "model_id = {model: i for i, model in enumerate(models)}\n",
    "id_model = {i: model for i, model in enumerate(models)}\n",
    "dataset_id = {dataset: i for i, dataset in enumerate(datasets)}\n",
    "id_dataset = {i: dataset for i, dataset in enumerate(datasets)}\n",
    "method_id = {method: i for i, method in enumerate(methods)}\n",
    "id_method = {i: method for i, method in enumerate(methods)}\n",
    "marker_list = ['o', 's', '^', 'v', '>', '<', 'd', 'p', '*', 'h', 'H', 'x', '+', '.', ',', '|', '_']\n",
    "color_list = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "print(f'model_id: {model_id}')\n",
    "print(f'dataset_id: {dataset_id}')\n",
    "print(f'method_id: {method_id}')\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 4 * n_rows))\n",
    "axes = np.atleast_2d(axes) # to avoid plt.subplots returns an array that is not two dimension when n_rows or n_cols is not greater than one\n",
    "for line_data in selected_line_data:\n",
    "    row_id = model_id[line_data.model]\n",
    "    col_id = dataset_id[line_data.dataset]\n",
    "    ax = axes[row_id][col_id]\n",
    "    i = method_id[line_data.method]\n",
    "    color = color_list[i]\n",
    "    marker = marker_list[i]\n",
    "    \n",
    "    x = line_data.request_rates\n",
    "    y = line_data.slo_attainment\n",
    "    ax.plot(x, y, color=color, marker=marker)\n",
    "    draw_slo_vertical_line(x, y, slo_target=0.9, ax=ax, color=color, linestyle='--', alpha=0.75)\n",
    "    \n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        ax = axes[i][j]\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        \n",
    "        formatter = FuncFormatter(lambda val, pos: f'{val * 100:.0f}')\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "        ax.axhline(y=0.9, color=\"gray\", linestyle=\"--\")\n",
    "        \n",
    "        if j == 0: \n",
    "            ax.set_ylabel('SLO Attainment', fontsize=18)\n",
    "            ax.text(-0.2, 0.5, id_model[i], transform=ax.transAxes, ha='right', va='center', rotation=90, fontsize=18)\n",
    "        if i == n_rows - 1:\n",
    "            axes[i][j].set_xlabel('Request Rate (req/s)', fontsize=18)\n",
    "            ax.text(7, -0.3, id_dataset[j], ha='center', va='bottom', fontsize=18)\n",
    "            \n",
    "fig.legend(\n",
    "    [Line2D([0], [0], color=color_list[i], marker=marker_list[i]) for i in range(len(method_id))],\n",
    "    [method for method, id in method_id.items()], \n",
    "    loc='upper center', ncol=2, fontsize=18, frameon=False, bbox_to_anchor=(0.5, 1.1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92c40e32060757cc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "fig.savefig(os.path.join(figures_dir, \"slo_attainment.pdf\"), bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bee407a1cc2e368d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for line_data in selected_line_data:\n",
    "    print(line_data.method, line_data.model, line_data.dataset, line_data.slo_attainment)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "576fb22f18f77620",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "df048af0d7d07063"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
